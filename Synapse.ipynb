{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "deriva_py = '/Users/carl/Repos/deriva-py/deriva_common'\n",
    "identifier = '/Users/carl/Repos/identifiers' \n",
    "\n",
    "sys.path\n",
    "sys.path.extend([deriva_py, identifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VersionedCatalog'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e41d777c6929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mderiva_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHatracStore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mErmrestCatalog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_credential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVersionedCatalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'VersionedCatalog'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import synapse_utils\n",
    "import os\n",
    "\n",
    "from deriva_common import HatracStore, ErmrestCatalog, get_credential\n",
    "\n",
    "import IPython.core.debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up debugging and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbg = IPython.core.debugger.Pdb\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# Configuring the logger for debug level will display the uri's generated by the api\n",
    "debug = False\n",
    "if debug:\n",
    "    import logging\n",
    "    logger = logging.getLogger('deriva_common.datasets')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to synapse catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to use Deriva authentication agent before executing this\n",
    "credential = get_credential(\"synapse.isrd.isi.edu\")\n",
    "\n",
    "objectstore = HatracStore('https','synapse.isrd.isi.edu',credentials=credential)\n",
    "catalog = ErmrestCatalog('https','synapse.isrd.isi.edu', 1, credentials=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Deriva datapath library to construct queries to the synapse catalog and retrieve the information about the current set of studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 28 studies\n"
     ]
    }
   ],
   "source": [
    "pb = catalog.getPathBuilder()\n",
    "\n",
    "# convenient name for the schema we care about.\n",
    "zebrafish = pb.Zebrafish\n",
    "synapse = pb.Synapse\n",
    "\n",
    "# Lets get some shortcuts for awkward table names.\n",
    "study_table = zebrafish.tables['Synaptic Pair Study']\n",
    "pair_table = zebrafish.tables['Image Pair Study']\n",
    "\n",
    "# Build up the path study->pair->behavior. \n",
    "# Make aliases for study and pair instances for later use.\n",
    "# We use the left join to make sure we get controls, which will be studies without behaviors.\n",
    "path = study_table.alias('study')\\\n",
    "    .link(pair_table.alias('pair'))\\\n",
    "    .link(zebrafish.Behavior, join_type = 'left', on=(pair_table.Subject == zebrafish.Behavior.Subject))\n",
    "    \n",
    "# Now lets go back an pick up the protocols which are associated with an image.\n",
    "# Each image has a protocol step, and from the step we can get the protocol.\n",
    "# Use the first image. \n",
    "path = path.pair.link(zebrafish.Image, on=path.pair.columns['Image 1'] == zebrafish.Image.ID)\\\n",
    "    .link(synapse.tables['Protocol Step'])\\\n",
    "    .link(synapse.Protocol)\n",
    "    \n",
    "# Now that we have build up the path, we can retrieve the set of studies and associated values\n",
    "study_entities = path.study.entities(path.study.Study, \n",
    "                                     path.pair.Subject, \n",
    "                                     path.Behavior.columns['Learned?'],\n",
    "                                     path.study.columns['Region 1 URL'],\n",
    "                                     path.study.columns['Region 2 URL'],\n",
    "                                     Protocol=path.Protocol.ID,)\n",
    "\n",
    "study_uri = study_entities.uri\n",
    "\n",
    "print('Identified %d studies' % len(study_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do some local manipulation of the studies in preperation to turning them into PANDAs.  Specifically, we will map the protocol name into the protocol type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "study_list = []\n",
    "\n",
    "protocol_types = {\n",
    "    'PrcDsy20160101A': 'aversion',  \n",
    "    'PrcDsy20170613A': 'conditioned', \n",
    "    'PrcDsy20170615A': 'unconditioned', \n",
    "    'PrcDsy20170613B': 'control'\n",
    "}\n",
    "\n",
    "for i in study_entities:\n",
    "    if protocol_types[i['Protocol']] == 'aversion':\n",
    "        i['Type'] = 'learner' if i['Learned?'] == True else 'nonlearner'\n",
    "    else:\n",
    "        i['Type'] = protocol_types[i['Protocol']]\n",
    "    study_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets map over the list of studies and for each study, retrieve the synapse data and turn into PANDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synapses = [synapse_utils.get_synapses(objectstore, study) for study in study_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up to do a 3D scatter plot of the synapse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a study\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "def plot_study(study):\n",
    "    '''\n",
    "    Create a 3D scatter plot of a study.\n",
    "    '''\n",
    "    before_synapses = go.Scatter3d(\n",
    "        x=study['Before']['X'],\n",
    "        y=study['Before']['Y'],\n",
    "        z=study['Before']['Z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            line=dict(\n",
    "            color='rgb(0,255,0)',\n",
    "            width=0.5\n",
    "            ),\n",
    "        opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    after_synapses = go.Scatter3d(\n",
    "        x=study['After']['X'],\n",
    "        y=study['After']['Y'],\n",
    "        z=study['After']['Z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            line=dict(\n",
    "                color='rgb(255,0,0)',\n",
    "                width=.5\n",
    "            ),\n",
    "        opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    data = [before_synapses, after_synapses]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot synapses from PANDAs....\n",
    "\n",
    "plot_study(synapses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a utility function to dump out all of the studies into a local directory.  \n",
    "This should eventually be eliminated in favor of just dumping out a BDBag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump out the synapses to a local directory\n",
    "\n",
    "destdir = '/Users/carl/Desktop'\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "try:\n",
    "    os.chdir(destdir)\n",
    "    synapse_utils.export_synapse_studies(objectstore, study_list)\n",
    "finally:\n",
    "    os.chdir(current_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MINID for the data set using the current version of the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'versioned_catalog'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-44a49768de05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mderiva_minid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mderiva_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderiva_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversioned_catalog\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVersionedCatalog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/identifiers/deriva_minid.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mderiva_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mErmrestCatalog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_credential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlquote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mderiva_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_hashes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mversioned_catalog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersionedCatalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlunparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'versioned_catalog'"
     ]
    }
   ],
   "source": [
    "import deriva_minid\n",
    "import deriva_common.deriva_common.versioned_catalog as vc\n",
    "\n",
    "vc = vc.VersionedCatalog(study_uri)\n",
    "\n",
    "config = mca.parse_config(args.config)\n",
    "server = config['server']\n",
    "email = config['email']\n",
    "code = config['code']\n",
    "test = True\n",
    "\n",
    "minid = create_catalog_minid(vc, server, email, code, title=args.title, test=test)\n",
    "\n",
    "print(\"Created new identifier: %s\" % minid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
