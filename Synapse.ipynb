{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "deriva_py = '/Users/carl/Repos/deriva-py/deriva_common'\n",
    "\n",
    "sys.path\n",
    "sys.path.extend([deriva_py])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from deriva_common import HatracStore, ErmrestCatalog, get_credential\n",
    "\n",
    "import IPython.core.debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up debugging and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbg = IPython.core.debugger.Pdb\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# Configuring the logger for debug level will display the uri's generated by the api\n",
    "debug = False\n",
    "if debug:\n",
    "    import logging\n",
    "    logger = logging.getLogger('deriva_common.datasets')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_synapses(synapsefiles, study):\n",
    "   \n",
    "    '''\n",
    "     synapsefile: a HatracStore object\n",
    "     study: a dictionary that has URLs for the two images, before and after\n",
    "     \n",
    "     returns two pandas that have the synapses in them.\n",
    "     ''' \n",
    "\n",
    "    try:\n",
    "        # Get a path for a tempory file to store HATRAC results \n",
    "        path = os.path.join(tempfile.mkdtemp(), 'image')\n",
    "        \n",
    "        # Get the before image from hatrac, be careful in case its missing\n",
    "        if study['Region 1 URL']:\n",
    "            synapsefiles.get_obj(study['Region 1 URL'], destfilename=path)\n",
    "            img1 = pd.read_csv(path)\n",
    "            img1.drop(img1.index[0],inplace=True)\n",
    "        else:\n",
    "            img1 = None\n",
    "        \n",
    "        # Get the after image from hatrac, be careful in case its missing\n",
    "        if study['Region 2 URL']:\n",
    "            synapsefiles.get_obj(study['Region 2 URL'], destfilename=path)\n",
    "            img2 = pd.read_csv(path)\n",
    "            img2.drop(img2.index[0],inplace=True)\n",
    "        else:\n",
    "            img2 = None\n",
    "    finally:\n",
    "        shutil.rmtree(os.path.dirname(path))\n",
    "    return {'before':img1, 'after': img2, 'type': study['type']}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a study\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "def plot_study(study):\n",
    "    '''\n",
    "    Create a 3D scatter plot of a study.\n",
    "    '''\n",
    "    trace1 = go.Scatter3d(\n",
    "        x=study['before']['X'],\n",
    "        y=study['before']['Y'],\n",
    "        z=study['before']['Z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            line=dict(\n",
    "            color='rgb(0,255,0)',\n",
    "            width=0.5\n",
    "            ),\n",
    "        opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    trace2 = go.Scatter3d(\n",
    "        x=study['after']['X'],\n",
    "        y=study['after']['Y'],\n",
    "        z=study['after']['Z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            line=dict(\n",
    "                color='rgb(255,0,0)',\n",
    "                width=.5\n",
    "            ),\n",
    "        opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    data = [trace1, trace2]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to synapse catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use Deriva authentication agent before executing this\n",
    "credential = get_credential(\"synapse.isrd.isi.edu\")\n",
    "\n",
    "objectstore = HatracStore('https','synapse.isrd.isi.edu',credentials=credential)\n",
    "catalog = ErmrestCatalog('https','synapse.isrd.isi.edu', 1, credentials=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "54\n",
      "{'Study': 6023, 'Subject': 'ZfDsy20160116A'}\n"
     ]
    }
   ],
   "source": [
    "pb = catalog.getPathBuilder()\n",
    "\n",
    "# conenient name for the schema we care about.\n",
    "zebrafish = pb.Zebrafish\n",
    "\n",
    "#build up the path....\n",
    "path = zebrafish.tables['Synaptic Pair Study'].alias('study')\\\n",
    "    .link(zebrafish.tables['Image Pair Study'].alias('pair'))\\\n",
    "    .link(zebrafish.Image) \n",
    "\n",
    "pair_entities = path.pair.entities()\n",
    "image_entities = path.Image.entities()\n",
    "study_entities = path.study.entities(path.study.Study, path.pair.Subject)\n",
    "\n",
    "print(len(pair_entities))\n",
    "print(len(image_entities))\n",
    "\n",
    "print(study_entities[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get set of studies as a list from the Synaptic Pair Study table. \n",
    "\n",
    "ds = datasets.from_catalog(catalog)\n",
    "\n",
    "# Get a couple of useful tables....\n",
    "behaviors = ds.Zebrafish.Behavior\n",
    "pairs = ds.Zebrafish.tables['Image Pair Study']\n",
    "studies = ds.Zebrafish.tables['Synaptic Pair Study']\n",
    "images = ds.Zebrafish.Ima\n",
    "\n",
    "protocol_steps = ds.Synapse.tables['Protocol Step']\n",
    "\n",
    "B = behaviors.as_('B')\n",
    "S = studies.as_('S')\n",
    "I = images.as_('I')\n",
    "P = pairs.as_('P')\n",
    "\n",
    "# This doesn't work....\n",
    "#foo = S \\\n",
    "#    .join(P) \\\n",
    "#    .join(I) \\\n",
    "#    .join(B, on=(I.Subject == B.Subject)) \\\n",
    "#    .select(S.Study, \\\n",
    "#            I.Subject, \\\n",
    "#            B.columns['Learned?'], \n",
    "#            S.columns['Region 1 URL'], \\\n",
    "#            S.columns['Region 2 URL'])\n",
    "\n",
    "# Image->Protocol Step[ID]\n",
    "study_query = S \\\n",
    "    .join(P) \\\n",
    "    .join(I) \\\n",
    "    .join(B, on=(I.Subject == behaviors.Subject)) \\\n",
    "    .join(protocol_steps, on=(I.Step == protocol_steps.ID)) \\\n",
    "    .select(S.Study, \\\n",
    "            I.Subject, \\\n",
    "            B.columns['Learned?'], \n",
    "            S.columns['Region 1 URL'], \\\n",
    "            S.columns['Region 2 URL'])\n",
    "          \n",
    "study_list = list(study_query)\n",
    "\n",
    "# Hack in study type, this should be replaced with a join in the previous expression.\n",
    "for i in study_list:\n",
    "    i['type'] = 'control'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'PrcDsy20160101A-tpt1': 'aversion',  'PrcDsy20160101A-tpt2': 'aversion',  \n",
    "    'PrcDsy20170613A-tpt1': 'conditioned', 'PrcDsy20170613A-tpt2' : 'conditioned',\n",
    "    'PrcDsy20170615A-tpt1': 'unconditioned',  'PrcDsy20170615A-tpt1':'uncondinioned' \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synapses = [get_synapses(objectstore, study) for study in study_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_study(synapses[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
