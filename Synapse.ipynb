{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "deriva_py = '/Users/carl/Repos/deriva-py/deriva_common'\n",
    "identifier = '/Users/carl/Repos/identifiers' \n",
    "\n",
    "sys.path\n",
    "sys.path.extend([deriva_py, identifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import synapse_utils\n",
    "import os\n",
    "\n",
    "from deriva_common import HatracStore, ErmrestCatalog, get_credential\n",
    "\n",
    "import IPython.core.debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up debugging and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg = IPython.core.debugger.Pdb\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# Configuring the logger for debug level will display the uri's generated by the api\n",
    "debug = False\n",
    "if debug:\n",
    "    import logging\n",
    "    logger = logging.getLogger('deriva_common.datasets')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to synapse catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to use Deriva authentication agent before executing this\n",
    "credential = get_credential(\"synapse.isrd.isi.edu\")\n",
    "\n",
    "objectstore = HatracStore('https','synapse.isrd.isi.edu',credentials=credential)\n",
    "catalog = ErmrestCatalog('https','synapse.isrd.isi.edu', 1, credentials=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Deriva datapath library to construct queries to the synapse catalog and retrieve the information about the current set of studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 28 studies\n"
     ]
    }
   ],
   "source": [
    "pb = catalog.getPathBuilder()\n",
    "\n",
    "# convenient name for the schema we care about.\n",
    "zebrafish = pb.Zebrafish\n",
    "synapse = pb.Synapse\n",
    "\n",
    "# Lets get some shortcuts for awkward table names.\n",
    "study_table = zebrafish.tables['Synaptic Pair Study']\n",
    "pair_table = zebrafish.tables['Image Pair Study']\n",
    "\n",
    "# Build up the path study->pair->behavior. \n",
    "# Make aliases for study and pair instances for later use.\n",
    "# We use the left join to make sure we get controls, which will be studies without behaviors.\n",
    "path = study_table.alias('study')\\\n",
    "    .link(pair_table.alias('pair'))\\\n",
    "    .link(zebrafish.Behavior, join_type = 'left', on=(pair_table.Subject == zebrafish.Behavior.Subject))\n",
    "    \n",
    "# Now lets go back an pick up the protocols which are associated with an image.\n",
    "# Each image has a protocol step, and from the step we can get the protocol.\n",
    "# Use the first image. \n",
    "path = path.pair.link(zebrafish.Image, on=path.pair.columns['Image 1'] == zebrafish.Image.ID)\\\n",
    "    .link(synapse.tables['Protocol Step'])\\\n",
    "    .link(synapse.Protocol)\n",
    "    \n",
    "# Now that we have build up the path, we can retrieve the set of studies and associated values\n",
    "study_entities = path.study.entities(path.study.Study, \n",
    "                                     path.pair.Subject, \n",
    "                                     path.Behavior.columns['Learned?'],\n",
    "                                     path.study.columns['Region 1 URL'],\n",
    "                                     path.study.columns['Region 2 URL'],\n",
    "                                     Protocol=path.Protocol.ID,)\n",
    "\n",
    "study_uri = study_entities.uri\n",
    "\n",
    "print('Identified %d studies' % len(study_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do some local manipulation of the studies in preperation to turning them into PANDAs.  Specifically, we will map the protocol name into the protocol type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "study_list = []\n",
    "\n",
    "protocol_types = {\n",
    "    'PrcDsy20160101A': 'aversion',  \n",
    "    'PrcDsy20170613A': 'conditioned', \n",
    "    'PrcDsy20170615A': 'unconditioned', \n",
    "    'PrcDsy20170613B': 'control'\n",
    "}\n",
    "\n",
    "for i in study_entities:\n",
    "    if protocol_types[i['Protocol']] == 'aversion':\n",
    "        i['Type'] = 'learner' if i['Learned?'] == True else 'nonlearner'\n",
    "    else:\n",
    "        i['Type'] = protocol_types[i['Protocol']]\n",
    "    study_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets map over the list of studies and for each study, retrieve the synapse data and turn into PANDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synapses = [synapse_utils.get_synapses(objectstore, study) for study in study_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up to do a 3D scatter plot of the synapse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a study\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "def plot_study(study):\n",
    "    '''\n",
    "    Create a 3D scatter plot of a study.\n",
    "    '''\n",
    "    before_synapses = go.Scatter3d(\n",
    "        x=study['Before']['X'],\n",
    "        y=study['Before']['Y'],\n",
    "        z=study['Before']['Z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            line=dict(\n",
    "            color='rgb(0,255,0)',\n",
    "            width=0.5\n",
    "            ),\n",
    "        opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    after_synapses = go.Scatter3d(\n",
    "        x=study['After']['X'],\n",
    "        y=study['After']['Y'],\n",
    "        z=study['After']['Z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            line=dict(\n",
    "                color='rgb(255,0,0)',\n",
    "                width=.5\n",
    "            ),\n",
    "        opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    data = [before_synapses, after_synapses]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot synapses from PANDAs....\n",
    "\n",
    "plot_study(synapses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a utility function to dump out all of the studies into a local directory.  \n",
    "This should eventually be eliminated in favor of just dumping out a BDBag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump out the synapses to a local directory\n",
    "\n",
    "destdir = '/Users/carl/Desktop'\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "try:\n",
    "    os.chdir(destdir)\n",
    "    synapse_utils.export_synapse_studies(objectstore, study_list)\n",
    "finally:\n",
    "    os.chdir(current_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MINID for the data set using the current version of the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checksum path is: /attribute/study:=Zebrafish:Synaptic%20Pair%20Study/pair:=Zebrafish:Image%20Pair%20Study/Behavior:=left(Subject)=(Zebrafish:Behavior:Subject)/$pair/Image:=(pair:Image%201)=(Zebrafish:Image:ID)/Protocol%2520Step:=Synapse:Protocol%20Step/Protocol:=Synapse:Protocol/$study/study:Study,pair:Subject,Behavior:Learned%3F,study:Region%201%20URL,study:Region%202%20URL,Protocol:=Protocol:ID\n"
     ]
    },
    {
     "ename": "MINIDError",
     "evalue": "MINID for this catalog version already exists: ark:/99999/fk49g5xv8h",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMINIDError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-4a3509bf453b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mminid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderiva_minid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_catalog_minid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminid_server\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Latest synapse data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created new identifier: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mminid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/identifiers/deriva_minid.py\u001b[0m in \u001b[0;36mcreate_catalog_minid\u001b[0;34m(catalog, minidserver, email, code, title, test, key)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# register file or display info about the entity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mMINIDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MINID for this catalog version already exists: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMINIDError\u001b[0m: MINID for this catalog version already exists: ark:/99999/fk49g5xv8h"
     ]
    }
   ],
   "source": [
    "import deriva_minid\n",
    "from deriva_common import VersionedCatalog\n",
    "import minid_client.minid_client_api as mca\n",
    "\n",
    "vc = VersionedCatalog(study_uri)\n",
    "\n",
    "config = mca.parse_config(mca.DEFAULT_CONFIG_FILE)\n",
    "minid_server = config['minid_server']\n",
    "email = config['email']\n",
    "code = config['code']\n",
    "test = True\n",
    "title = None\n",
    "\n",
    "minid = deriva_minid.create_catalog_minid(vc, minid_server, email, code, title='Latest synapse data', test=test)\n",
    "\n",
    "print(\"Created new identifier: %s\" % minid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
